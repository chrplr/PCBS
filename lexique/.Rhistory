install.packages("tidyverse")
require(readr)
lex = read_delim("Lexique382.tsv", sep="\t")
require(readr)
lex = read_delim("Lexique382.tsv", delim="\t")
require(readr)
lex = read_delim("Lexique382.tsv", delim="\t")
head(lex)
head(lex, 25)
require(readr)
lex = read_delim("Lexique382.tsv", delim="\t")
head(lex, 25)
require(readr)
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lex, 25)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lex, ortho %in% items)
head(selection)
View(selection)
selection = subset(lexique, cgram=='NOM' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
View(selection)
selection = subset(lexique, cgram=='NOM' & nombre != 'p' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
lexique %>% filter(!grepl("^[aeiou]", ortho))
require(tidyverse)  # you must have ran "install.pacakages('tidyverse')" earlier
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lex, 25)
lexique %>% filter(!grepl("^[aeiou]", ortho))
lexique %>% filter(grepl("tion$", ortho))
lexique %>% filter(cgram == 'VER') %>% filter(!grepl("ent"), ortho)
lexique %>% filter('VER', cgram) %>% filter(!grepl("ent"), ortho)
lexique %>% filter(cgram == 'VER') %>% filter(!grepl("ent"), ortho)
lexique %>% filter(!grepl("ent"), ortho)  %>% group_by(cgram)
lexique %>% filter(!grepl("ent$"), ortho)
require(tidyverse)  # you must have ran "install.pacakages('tidyverse')" earlier
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lex, 25)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lex, ortho %in% items)
head(selection)
write_tsv(selection, 'selection.tsv')
selection = subset(lexique, cgram=='NOM' & nombre != 'p' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
head(selection)
lexique %>% filter(grepl("tion$", ortho))
lexique %>% filter(!grepl("ent$"), ortho)
lexique %>% filter(!grepl("ent$", ortho)
lexique %>% filter(!grepl("ent$", ortho))
lexique %>% filter(!grepl("ent$", ortho))  %>% group_by(cgram)
lexique %>% filter(!grepl("ent$", ortho)) -> selection3
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) -> selection3
head(selection3)
View(selection3)
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) %>% group_by(cgram) -> selection3
head(selection3)
View(selection3)
View(selection)
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) -> selection4
head(selection4)
lexique %>% filter('[ptkbdg][ptkbdg]', phon) -> selection3
lexique %>% filter(grepl('[ptkbdg][ptkbdg]', phon)) -> selection3
head(selection3)
?read_delim
require(tidyverse)  # you must have ran "install.packages('tidyverse')" earlier
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lexique, 25)
?scan
a=scan(what='characters')
a=scan(what='characters')
require(tidyverse)  # you must have ran "install.packages('tidyverse')" earlier
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lexique, 25)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
write_tsv(selection, 'selection.tsv')
items = scan(what='characters')
selection = subset(lexique, cgram=='NOM' & nombre != 'p' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
head(selection)
lexique %>% filter(grepl("tion$", ortho)) -> selection2
head(selection2)
write_tsv(selection2, 'mots-en-tion.tsv')
lexique %>% filter(grepl('.[ptkbdg][ptkbdg]', phon)) -> selection3
head(selection3)
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) -> selection4
head(selection4)
require(tidyverse)  # you must have ran "install.packages('tidyverse')" earlier
lexique = read_delim("Lexique382.tsv", delim="\t")
head(lexique, 25)
install.packages(c("rjson", "tidyverse"))
source('~/4_code/openlexicon/datasets-info/fetch_datasets.R')
get_lexique382()
get_lexique383()
q()
install.packages(c('rjson', 'tidyverse'))
require(tidyverse)
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique382()
lexique1 <- subset(lexique, freqlivres > 0.5)
lexique1$logfreq <- log10(lexique1$freqlivres)
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
write_tsv(selection, 'selection.tsv')
items = scan(what='characters')
selection <- subset(lexique, ortho %in% items)
liste <- scan('liste.txt', what='characters')
selection <- subset(lexique, ortho %in% liste)
selection = subset(lexique, cgram=='NOM' & nombre != 'p' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
head(selection)
lexique %>% filter(grepl("tion$", ortho)) -> selection2
head(selection2)
write_tsv(selection2, 'mots-en-tion.tsv')
lexique %>% filter(grepl('.[ptkbdg][ptkbdg]', phon)) -> selection3
head(selection3)
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) -> selection4
head(selection4)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
subtlexus <- readRDS(fetch_dataset('SUBTLEX-US', format='rds')$datatables[[1]])
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique383()
lexique1 = subset(lexique, freqlivres > 0.5)
lexique1$logfreq <- log10(lexique1$freqlivres)
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
b1 <- subset(lexique1, ((logfreq < 0.1) & (cgram == 'NOM') & (islem==1)), c('ortho',  'freqlivres', 'logfreq'))
b1[sample(1:nrow(b1), 10),]
b2 <- subset(lexique1, ((logfreq > 1) & (logfreq < 1.1) & (cgram == 'NOM') & (islem==1)), c('ortho',  'freqlivres', 'logfreq'))
b2[sample(1:nrow(b2), 10),]
b3 <- subset(lexique1, ((logfreq > 1.5) & (logfreq < 1.6) & (cgram == 'NOM') & (islem==1)), c('ortho',  'freqlivres', 'logfreq'))
b3[sample(1:nrow(b3), 10),]
b4 <- subset(lexique1, ((logfreq > 2.0) & (logfreq < 2.1) & (cgram == 'NOM') & (islem==1)), c('ortho',  'freqlivres', 'logfreq'))
b4[sample(1:nrow(b4), 10),]
b5 <- subset(lexique1, ((logfreq > 2.5) & (logfreq < 2.6) & (cgram == 'NOM') & (islem==1)), c('ortho',  'freqlivres', 'logfreq'))
b5[sample(1:nrow(b5), 10),]
lexique1$logfreqfilms = log10(lexique1$freqfilms2)
with(lexique1, plot(logfreq, logfreqfilms, pch='.'))
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
lexique1 <- subset(lexique, freqlivres > 0.5)
lexique1$logfreq <- log10(lexique1$freqlivres)
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
write_tsv(selection, 'selection.tsv')
install.packages(c('rjson', 'tidyverse'))
require(tidyverse)
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique383()
lexique1 <- subset(lexique, freqlivres > 0.5)
lexique1$logfreq <- log10(lexique1$freqlivres)
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
write_tsv(selection, 'selection.tsv')
items = scan(what='characters')
selection <- subset(lexique, ortho %in% items)
liste <- scan('liste.txt', what='characters')
selection <- subset(lexique, ortho %in% liste)
selection = subset(lexique, cgram=='NOM' & nombre != 'p' & nblettres==5 & freqlivres > 10 & freqlivres < 100)
head(selection)
lexique %>% filter(grepl("tion$", ortho)) -> selection2
head(selection2)
write_tsv(selection2, 'mots-en-tion.tsv')
lexique %>% filter(grepl('.[ptkbdg][ptkbdg]', phon)) -> selection3
head(selection3)
lexique %>% filter(nblettres == 8) %>% filter(!grepl("ent$", ortho)) -> selection4
head(selection4)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
subtlexus <- readRDS(fetch_dataset('SUBTLEX-US', format='rds')$datatables[[1]])
require(tidyverse)
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique383()
lexique1 <- subset(lexique, freqlivres > 0.5)
lexique1$logfreq <- log10(lexique1$freqlivres)
with(lexique1, {
histdata <- hist(logfreq, plot=FALSE, nclass=50)
plot(histdata$breaks[-1], histdata$count, log="y", type='h', lwd=10, lend=2, las=1, xlab='log10(freqlivres)', ylab='count')
}
)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
items <- c('bateau', 'avion', 'maison', 'arbre')
selection <- subset(lexique, ortho %in% items)
head(selection)
require(tidyverse)
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique383_rds()
require(tidyverse)
require(rjson)
source('https://raw.githubusercontent.com/chrplr/openlexicon/master/datasets-info/fetch_datasets.R')
lexique <- get_lexique383_rds()
source('~/4_code/openlexicon/datasets-info/fetch_datasets.R')
get_lexique383_rds()
x=get_lexique383_rds()
x=get_lexique383_rds()
x=get_lexique383_rds()
source('~/4_code/openlexicon/datasets-info/fetch_datasets.R')
x=get_lexique383_rds()
get_subtlex.us()
source('~/4_code/openlexicon/datasets-info/fetch_datasets.R')
get_worldlex.english_rds()
get_worldlex.english_rds()
get_lexique383_rds()
get_lexique383_rds()
